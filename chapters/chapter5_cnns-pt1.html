
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chapter 5: Introduction to Convolutional Neural Networks &#8212; Deep Learning with PyTorch</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Chapter 6: Advanced Convolutional Neural Networks" href="chapter6_cnns-pt2.html" />
    <link rel="prev" title="Chapter 4: Training Neural Networks" href="chapter4_neural-networks-pt2.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Deep Learning with PyTorch</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Deep Learning with PyTorch
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Chapters
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter1_gradient-descent.html">
   Chapter 1: Optimization &amp; Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter2_stochastic-gradient-descent.html">
   Chapter 2: Stochastic Gradient Descent
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter3_pytorch-neural-networks-pt1.html">
   Chapter 3: Introduction to Pytorch &amp; Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter4_neural-networks-pt2.html">
   Chapter 4: Training Neural Networks
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Chapter 5: Introduction to Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter6_cnns-pt2.html">
   Chapter 6: Advanced Convolutional Neural Networks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter7_advanced-deep-learning.html">
   Chapter 7: Advanced Deep Learning
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="appendixA_gradients.html">
   Appendix A: Gradients Review
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="appendixB_logistic-loss.html">
   Appendix B: Logistic Loss
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="appendixC_computing-derivatives.html">
   Appendix C: Computing Derivatives
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="appendixD_bitmoji-CNN.html">
   Appendix D: Creating a CNN to Predict Bitmojis
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  <a href="https://www.tomasbeuzen.com/">Tomas Beuzen</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/chapters/chapter5_cnns-pt1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/TomasBeuzen/deep-learning-with-pytorch"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/TomasBeuzen/deep-learning-with-pytorch/main?urlpath=tree/chapters/chapter5_cnns-pt1.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chapter-outline">
   Chapter Outline
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#chapter-learning-objectives">
   Chapter Learning Objectives
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convolutional-neural-networks-cnns">
   1. Convolutional Neural Networks (CNNs)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation">
     1.1. Motivation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutions-and-filters">
     1.2. Convolutions and Filters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cooking-up-a-cnn">
   2. Cooking up a CNN
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ingredient-1-convolutional-layers">
     2.1. Ingredient 1: Convolutional Layers
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ingredient-2-flattening">
     2.2. Ingredient 2: Flattening
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ingredient-3-pooling">
     2.3. Ingredient 3: Pooling
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-cnn-recipe-book">
   3. The CNN Recipe Book
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cnn-vs-fully-connected-nn">
   4. CNN vs Fully Connected NN
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><img alt="" src="../_images/banner.png" /></p>
<div class="section" id="chapter-5-introduction-to-convolutional-neural-networks">
<h1>Chapter 5: Introduction to Convolutional Neural Networks<a class="headerlink" href="#chapter-5-introduction-to-convolutional-neural-networks" title="Permalink to this headline">¬∂</a></h1>
<p><strong>By <a class="reference external" href="https://www.tomasbeuzen.com/">Tomas Beuzen</a> üöÄ</strong></p>
<p><img alt="" src="../_images/block.png" /></p>
<div class="section" id="chapter-outline">
<h2>Chapter Outline<a class="headerlink" href="#chapter-outline" title="Permalink to this headline">¬∂</a></h2>
<hr><div class="toc"><ul class="toc-item"><li><span><a href="#chapter-learning-objectives" data-toc-modified-id="Chapter-Learning-Objectives-2">Chapter Learning Objectives</a></span></li><li><span><a href="#imports" data-toc-modified-id="Imports-3">Imports</a></span></li><li><span><a href="#convolutional-neural-networks-cnns" data-toc-modified-id="1.-Convolutional-Neural-Networks-(CNNs)-4">1. Convolutional Neural Networks (CNNs)</a></span></li><li><span><a href="#cooking-up-a-cnn" data-toc-modified-id="2.-Cooking-up-a-CNN-5">2. Cooking up a CNN</a></span></li><li><span><a href="#the-cnn-recipe-book" data-toc-modified-id="3.-The-CNN-Recipe-Book-6">3. The CNN Recipe Book</a></span></li><li><span><a href="#cnn-vs-fully-connected-nn" data-toc-modified-id="4.-CNN-vs-Fully-Connected-NN-7">4. CNN vs Fully Connected NN</a></span></li></ul></div></div>
<div class="section" id="chapter-learning-objectives">
<h2>Chapter Learning Objectives<a class="headerlink" href="#chapter-learning-objectives" title="Permalink to this headline">¬∂</a></h2>
<hr><ul class="simple">
<li><p>Describe the terms convolution, kernel/filter, pooling, and flattening</p></li>
<li><p>Explain how convolutional neural networks (CNNs) work</p></li>
<li><p>Calculate the number of parameters in a given CNN architecture</p></li>
<li><p>Create a CNN in <code class="docutils literal notranslate"><span class="pre">PyTorch</span></code></p></li>
<li><p>Discuss the key differences between CNNs and fully connected NNs</p></li>
</ul>
</div>
<div class="section" id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¬∂</a></h2>
<hr><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">utils.plotting</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span> <span class="s1">&#39;axes.labelweight&#39;</span><span class="p">:</span> <span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="s1">&#39;axes.grid&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="convolutional-neural-networks-cnns">
<h2>1. Convolutional Neural Networks (CNNs)<a class="headerlink" href="#convolutional-neural-networks-cnns" title="Permalink to this headline">¬∂</a></h2>
<hr><div class="section" id="motivation">
<h3>1.1. Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">¬∂</a></h3>
<p>Up until now we‚Äôve been dealing with ‚Äúfully connected neural networks‚Äù meaning that every neuron in a given layer is connected to every neuron in the next layer. This has two key implications:</p>
<ol class="simple">
<li><p>It results in a LOT of parameters.</p></li>
<li><p>The order of our features doesn‚Äôt matter.</p></li>
</ol>
<p>Consider the simple image and fully connected network below:</p>
<p><img alt="" src="../_images/cnn-1.png" /></p>
<p>Every input node is connected to every node in the next layer - is that really necessary? When you look at this image, how do you know that it‚Äôs me?</p>
<ul class="simple">
<li><p>You notice the structure in the image (there‚Äôs a face, shoulders, a smile, etc.)</p></li>
<li><p>You notice how different structures are positioned and related (the face is on top of the shoulders, etc.)</p></li>
<li><p>You probably use the shading (colour) to infer things about the image too but we‚Äôll talk more about that later.</p></li>
</ul>
<p>The point here is that <strong>the structure of our data (the pixels) is important</strong>. So maybe, we should have each hidden node only look at a small area of the image, like this:</p>
<p><img alt="" src="../_images/cnn-2.png" /></p>
<p>We have far fewer parameters now because we‚Äôre acknowledging that pixels that are far apart are probably not all that related and so don‚Äôt need to be connected. We‚Äôre seeing that structure is important here, so then why should I need to flatten my image at all? Let‚Äôs be crazy and not flatten the image, but instead, make our hidden layer a 2D matrix:</p>
<p><img alt="" src="../_images/cnn-3.png" /></p>
<p>We‚Äôre almost there!</p>
<p>As it stands, each group of 2 x 2 pixels has 4 unique weights associated with it (one for each pixel), which are being summed up into a single value in the hidden layer. But we don‚Äôt need the weights to be different for each group, we‚Äôre looking for <strong>structure</strong>, we don‚Äôt care if my face is in the top left or the bottom right, we‚Äôre just looking for a face!</p>
<p>Let‚Äôs summarise the weights into a weight ‚Äúfilter‚Äù:</p>
<p><img alt="" src="../_images/cnn-4.png" /></p>
<ul class="simple">
<li><p>Let‚Äôs see how the filter works</p></li>
<li><p>We‚Äôll display some arbitrary values for our pixels</p></li>
<li><p>The filter ‚Äúconvolves‚Äù over each group of pixels, multiplies corresponding elements and sums them up to give the values in the output nodes:</p></li>
</ul>
<p><img alt="" src="../_images/cnn-5.gif" /></p>
<p>As we‚Äôll see, we can add as many of these ‚Äúfilters‚Äù as we like to make more complex models that can identify more useful things:</p>
<p><img alt="" src="../_images/cnn-6.png" /></p>
<p>We just made a <strong>convolutional neural network</strong> (CNN). Instead of fully-connected hidden nodes, we have 2D filters that we ‚Äúconvolve‚Äù over our input data. This has two key advantages:</p>
<ol class="simple">
<li><p>We have less parameters than a fully connected network.</p></li>
<li><p>We preserve the useful structure of our data.</p></li>
</ol>
</div>
<div class="section" id="convolutions-and-filters">
<h3>1.2. Convolutions and Filters<a class="headerlink" href="#convolutions-and-filters" title="Permalink to this headline">¬∂</a></h3>
<p>Convolution really just means ‚Äúto pass over the data‚Äù. What are we ‚Äúpassing‚Äù? Our filters - which are also called <strong>kernels</strong>. Here‚Äôs another gif like the one we saw earlier:</p>
<p><img alt="" src="../_images/conv-1.gif" /></p>
<blockquote>
<div><p>Source: modified after <a class="reference external" href="https://theano-pymc.readthedocs.io/en/latest/tutorial/conv_arithmetic.html">theano-pymc.readthedocs.io</a>.</p>
</div></blockquote>
<p>So how does this help us extract structure from the data? Well let‚Äôs see some examples!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;img/tom_bw.png&quot;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_21_0.png" src="../_images/chapter5_cnns-pt1_21_0.png" />
</div>
</div>
<p>We can blur this image by applying a filter with the following weights:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} 0.0625 &amp; 0.125 &amp; 0.0625 \\ 0.125 &amp; 0.25 &amp; 0.125 \\ 0.0625 &amp; 0.125 &amp; 0.0625 \end{bmatrix}\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">0.0625</span><span class="p">,</span>  <span class="mf">0.1250</span><span class="p">,</span>  <span class="mf">0.0625</span><span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.1250</span><span class="p">,</span>  <span class="mf">0.2500</span><span class="p">,</span>  <span class="mf">0.1250</span><span class="p">],</span>
                         <span class="p">[</span> <span class="mf">0.0625</span><span class="p">,</span>  <span class="mf">0.1250</span><span class="p">,</span>  <span class="mf">0.0625</span><span class="p">]]]])</span>
<span class="n">plot_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_23_0.png" src="../_images/chapter5_cnns-pt1_23_0.png" />
</div>
</div>
<p>How about this one:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} -2 &amp; -1 &amp; 0 \\ -1 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 2 \end{bmatrix}\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span>  <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
                         <span class="p">[</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">],</span>
                         <span class="p">[</span>  <span class="mi">0</span><span class="p">,</span>   <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">]]]])</span>
<span class="n">plot_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_25_0.png" src="../_images/chapter5_cnns-pt1_25_0.png" />
</div>
</div>
<p>One more:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix} -1 &amp; -1 &amp; -1 \\ -1 &amp; 8 &amp; -1 \\ -1 &amp; -1 &amp; -1 \end{bmatrix}\end{split}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span>  <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="o">-</span><span class="mi">1</span><span class="p">,</span>   <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                         <span class="p">[</span>  <span class="o">-</span><span class="mi">1</span><span class="p">,</span>   <span class="mi">8</span><span class="p">,</span>   <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                         <span class="p">[</span>  <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="o">-</span><span class="mi">1</span><span class="p">,</span>   <span class="o">-</span><span class="mi">1</span><span class="p">]]]])</span>
<span class="n">plot_conv</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_27_0.png" src="../_images/chapter5_cnns-pt1_27_0.png" />
</div>
</div>
<p><a class="reference external" href="https://setosa.io/ev/image-kernels/">Here‚Äôs a great website</a> where you can play around with other filters. We usually use <strong>odd numbers for filters</strong> so that they are applied symmetrically around our input data. Did you notice in the gif earlier that the output from applying our kernel was smaller than the input? Take a look again:</p>
<p><img alt="" src="../_images/conv-1.gif" /></p>
<blockquote>
<div><p>Source: modified after <a class="reference external" href="https://theano-pymc.readthedocs.io/en/latest/tutorial/conv_arithmetic.html">theano-pymc.readthedocs.io</a>.</p>
</div></blockquote>
<p>By default, our kernels are only applied where the filter fully fits on top of the input. But we can control this behaviour and the size of our output with:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">padding</span></code>: ‚Äúpads‚Äù the outside of the input 0‚Äôs to allow the kernel to reach the boundary pixels</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">strides</span></code>: controls how far the kernel ‚Äústeps‚Äù over pixels.</p></li>
</ul>
<p>Below is an example with:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">padding=1</span></code>: we have <code class="docutils literal notranslate"><span class="pre">1</span></code> layer of 0‚Äôs around our border</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">strides=(2,2)</span></code>: our kernel moves 2 data points to the right for each row, then moves 2 data points down to the next row</p></li>
</ul>
<p><img alt="" src="../_images/conv-2.gif" /></p>
<blockquote>
<div><p>Source: modified after <a class="reference external" href="https://theano-pymc.readthedocs.io/en/latest/tutorial/conv_arithmetic.html">theano-pymc.readthedocs.io</a>.</p>
</div></blockquote>
<p>We‚Äôll look more at these below.</p>
</div>
</div>
<div class="section" id="cooking-up-a-cnn">
<h2>2. Cooking up a CNN<a class="headerlink" href="#cooking-up-a-cnn" title="Permalink to this headline">¬∂</a></h2>
<hr><div class="section" id="ingredient-1-convolutional-layers">
<h3>2.1. Ingredient 1: Convolutional Layers<a class="headerlink" href="#ingredient-1-convolutional-layers" title="Permalink to this headline">¬∂</a></h3>
<p>I showed some example kernels above. In CNNs the actual values in <strong>the kernels are the weights your network will learn during training</strong>: your network will learn what structures are important for prediction.</p>
<p>In PyTorch, convolutional layers are defined as <code class="docutils literal notranslate"><span class="pre">torch.nn.Conv2d</span></code>, there are 5 important arguments we need to know:</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">in_channels</span></code>: how many features are we passing in. Our features are our colour bands, in greyscale, we have 1 feature, in colour, we have 3 channels.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">out_channels</span></code>: how many kernels do we want to use. Analogous to the number of hidden nodes in a hidden layer of a fully connected network.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">kernel_size</span></code>: the size of the kernel. Above we were using 3x3. Common sizes are 3x3, 5x5, 7x7.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">stride</span></code>: the ‚Äústep-size‚Äù of the kernel.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">padding</span></code>: the number of pixels we should pad to the outside of the image so we can get edge pixels.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1 kernel of (3,3)</span>
<span class="n">conv_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plot_convs</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_33_0.png" src="../_images/chapter5_cnns-pt1_33_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2 kernels of (3,3)</span>
<span class="n">conv_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plot_convs</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_34_0.png" src="../_images/chapter5_cnns-pt1_34_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 3 kernels of (5,5)</span>
<span class="n">conv_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plot_convs</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_35_0.png" src="../_images/chapter5_cnns-pt1_35_0.png" />
</div>
</div>
<p>If we use a kernel with no padding, our output image will be smaller as we noted earlier. Let‚Äôs demonstrate that by using a larger kernel now:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1 kernel of (51,51)</span>
<span class="n">conv_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">plot_convs</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_37_0.png" src="../_images/chapter5_cnns-pt1_37_0.png" />
</div>
</div>
<p>As we saw, we can add <code class="docutils literal notranslate"><span class="pre">padding</span></code> to the outside of the image to avoid this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1 kernel of (51,51) with padding</span>
<span class="n">conv_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">51</span><span class="p">,</span> <span class="mi">51</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plot_convs</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_39_0.png" src="../_images/chapter5_cnns-pt1_39_0.png" />
</div>
</div>
<blockquote>
<div><p>Setting <code class="docutils literal notranslate"><span class="pre">padding</span> <span class="pre">=</span> <span class="pre">kernel_size</span> <span class="pre">//</span> <span class="pre">2</span></code> will always result in an output the same shape as the input. Think about why this is‚Ä¶</p>
</div></blockquote>
<p>Finally, we also saw before how <code class="docutils literal notranslate"><span class="pre">strides</span></code> influence the size of the output:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1 kernel of (25,25) with stride of 3</span>
<span class="n">conv_layer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plot_convs</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">conv_layer</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/chapter5_cnns-pt1_42_0.png" src="../_images/chapter5_cnns-pt1_42_0.png" />
</div>
</div>
<p>With CNN we are no longer flattening our data, so what are our ‚Äúfeatures‚Äù?
Our features are called ‚Äúchannels‚Äù in CNN-lingo -&gt; they are like the colour channels in an image:</p>
<ul class="simple">
<li><p>A grayscale image has 1 feature/channel</p></li>
<li><p>A coloured image has 3 features/channel</p></li>
</ul>
<p><img alt="" src="../_images/channels-1.png" /></p>
<p><img alt="" src="../_images/channels-2.png" /></p>
<p>What‚Äôs important with CNNs is that the <strong>size of our input data does not impact how many parameters we have in our convolutonal layers</strong>. For example, your kernels don‚Äôt care how big your image is (i.e., 28 x 28 or 256 x 256), all that matters is:</p>
<ol class="simple">
<li><p>How many features (‚Äúchannels‚Äù) you have: <code class="docutils literal notranslate"><span class="pre">in_channels</span></code></p></li>
<li><p>How many filters you use in each layer: <code class="docutils literal notranslate"><span class="pre">out_channels</span></code></p></li>
<li><p>How big the filters are: <code class="docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
</ol>
<p>Let‚Äôs see some diagrams:</p>
<p><img alt="" src="../_images/cnn-7.png" /></p>
<p>For coloured images (3 channels):</p>
<p><img alt="" src="../_images/cnn-8.png" /></p>
</div>
<div class="section" id="ingredient-2-flattening">
<h3>2.2. Ingredient 2: Flattening<a class="headerlink" href="#ingredient-2-flattening" title="Permalink to this headline">¬∂</a></h3>
<p>With our brand new, shiny convolutional layers, we‚Äôre basically just passing images through the network - cool!</p>
<p>But we‚Äôre going to eventually want to do some regression or classification. That means that by the end of our network, we are going to need to <code class="docutils literal notranslate"><span class="pre">torch.nn.Flatten()</span></code> our images:</p>
<p><img alt="" src="../_images/cnn-9.png" /></p>
<p>Let‚Äôs make that simple CNN above in PyTorch:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span>
<span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
‚îú‚îÄSequential: 1-1                        [-1, 1]                   --
|    ‚îî‚îÄConv2d: 2-1                       [-1, 3, 100, 100]         30
|    ‚îî‚îÄReLU: 2-2                         [-1, 3, 100, 100]         --
|    ‚îî‚îÄConv2d: 2-3                       [-1, 2, 100, 100]         56
|    ‚îî‚îÄReLU: 2-4                         [-1, 2, 100, 100]         --
|    ‚îî‚îÄFlatten: 2-5                      [-1, 20000]               --
|    ‚îî‚îÄLinear: 2-6                       [-1, 1]                   20,001
==========================================================================================
Total params: 20,087
Trainable params: 20,087
Non-trainable params: 0
Total mult-adds (M): 0.85
==========================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 0.38
Params size (MB): 0.08
Estimated Total Size (MB): 0.50
==========================================================================================
</pre></div>
</div>
</div>
</div>
<p>Oh man! 20,000 parameters in that last layer, geez. Is there a way we can reduce this somehow? Glad you asked! See you in the next section.</p>
</div>
<div class="section" id="ingredient-3-pooling">
<h3>2.3. Ingredient 3: Pooling<a class="headerlink" href="#ingredient-3-pooling" title="Permalink to this headline">¬∂</a></h3>
<p>Pooling is how we can reduce the number of parameters we get out of a <code class="docutils literal notranslate"><span class="pre">torch.nn.Flatten()</span></code>. It‚Äôs pretty simple, we just aggregate the data, usually using the maximum or average of a window of pixels. Here‚Äôs an example of max pooling:</p>
<p><img alt="" src="../_images/pool.gif" /></p>
<blockquote>
<div><p>Source: modified after <a class="reference external" href="https://www.oreilly.com/radar/visualizing-convolutional-neural-networks/">www.oreilly.com/</a>.</p>
</div></blockquote>
<p>We use ‚Äúpooling layers‚Äù to reduce the shape of our image as it‚Äôs passing through the network. So when we eventually <code class="docutils literal notranslate"><span class="pre">torch.nn.Flatten()</span></code>, we‚Äôll have less features in that flattened layer! We can implement pooling with <code class="docutils literal notranslate"><span class="pre">torch.nn.MaxPool2d()</span></code>. Let‚Äôs try it out and reduce the number of parameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1250</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">()</span>
<span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
‚îú‚îÄSequential: 1-1                        [-1, 1]                   --
|    ‚îî‚îÄConv2d: 2-1                       [-1, 3, 100, 100]         30
|    ‚îî‚îÄReLU: 2-2                         [-1, 3, 100, 100]         --
|    ‚îî‚îÄMaxPool2d: 2-3                    [-1, 3, 50, 50]           --
|    ‚îî‚îÄConv2d: 2-4                       [-1, 2, 50, 50]           56
|    ‚îî‚îÄReLU: 2-5                         [-1, 2, 50, 50]           --
|    ‚îî‚îÄMaxPool2d: 2-6                    [-1, 2, 25, 25]           --
|    ‚îî‚îÄFlatten: 2-7                      [-1, 1250]                --
|    ‚îî‚îÄLinear: 2-8                       [-1, 1]                   1,251
==========================================================================================
Total params: 1,337
Trainable params: 1,337
Non-trainable params: 0
Total mult-adds (M): 0.41
==========================================================================================
Input size (MB): 0.04
Forward/backward pass size (MB): 0.27
Params size (MB): 0.01
Estimated Total Size (MB): 0.31
==========================================================================================
</pre></div>
</div>
</div>
</div>
<p>We reduced that last layer to 1,251 parameters. Nice job!</p>
</div>
</div>
<div class="section" id="the-cnn-recipe-book">
<h2>3. The CNN Recipe Book<a class="headerlink" href="#the-cnn-recipe-book" title="Permalink to this headline">¬∂</a></h2>
<hr><p>Here‚Äôs a CNN diagram of a famous architecture called <a class="reference external" href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a> (we‚Äôll talk more about ‚Äúfamous architectures‚Äù next Chapter):</p>
<p><img alt="" src="../_images/alexnet.png" /></p>
<p>You actually know what all of the above means now! But, deep learning and CNN architecture remains very much an art. Here is my general recipe book (based on experience, common practice, and popular pre-made architectures - more on those next chapter).</p>
<p>Typical ingredients (in order):</p>
<ul class="simple">
<li><p>Convolution layer(s): <code class="docutils literal notranslate"><span class="pre">torch.nn.Conv2d</span></code></p></li>
<li><p>Activation function: <code class="docutils literal notranslate"><span class="pre">torch.nn.ReLU</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.nn.Sigmoid</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.nn.Softplus</span></code>, etc.</p></li>
<li><p>(optional) Batch normalization: <code class="docutils literal notranslate"><span class="pre">torch.nn.BatchNorm2d</span></code> (more on that next Chapter)</p></li>
<li><p>(optional) Pooling: <code class="docutils literal notranslate"><span class="pre">torch.nn.MaxPool2d</span></code></p></li>
<li><p>(optional) Drop out: <code class="docutils literal notranslate"><span class="pre">torch.nn.Dropout</span></code></p></li>
<li><p>Flatten: <code class="docutils literal notranslate"><span class="pre">torch.nn.Flatten</span></code></p></li>
</ul>
</div>
<div class="section" id="cnn-vs-fully-connected-nn">
<h2>4. CNN vs Fully Connected NN<a class="headerlink" href="#cnn-vs-fully-connected-nn" title="Permalink to this headline">¬∂</a></h2>
<hr><p>As an example of the parameter savings introduced when using CNNs with structured data, let‚Äôs compare the Bitmoji classifier from last chapter, with an equivalent CNN version.</p>
<p>We‚Äôll replace all linear layers with convolutional layers with 3 kernels of size (3, 3) and will assume an image size of 128 x 128:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">linear_block</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">conv_block</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="n">output_channels</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
    <span class="p">)</span>

<span class="k">class</span> <span class="nc">NN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">linear_block</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
            <span class="n">linear_block</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
            <span class="n">linear_block</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
            <span class="n">linear_block</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
    
<span class="k">class</span> <span class="nc">CNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_channels</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">main</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="n">input_channels</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="n">conv_block</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">49152</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">NN</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">128</span> <span class="o">*</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="mi">128</span> <span class="o">*</span> <span class="mi">128</span><span class="p">,));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
‚îú‚îÄSequential: 1-1                        [-1, 1]                   --
|    ‚îî‚îÄSequential: 2-1                   [-1, 256]                 --
|    |    ‚îî‚îÄLinear: 3-1                  [-1, 256]                 4,194,560
|    |    ‚îî‚îÄReLU: 3-2                    [-1, 256]                 --
|    ‚îî‚îÄSequential: 2-2                   [-1, 128]                 --
|    |    ‚îî‚îÄLinear: 3-3                  [-1, 128]                 32,896
|    |    ‚îî‚îÄReLU: 3-4                    [-1, 128]                 --
|    ‚îî‚îÄSequential: 2-3                   [-1, 64]                  --
|    |    ‚îî‚îÄLinear: 3-5                  [-1, 64]                  8,256
|    |    ‚îî‚îÄReLU: 3-6                    [-1, 64]                  --
|    ‚îî‚îÄSequential: 2-4                   [-1, 16]                  --
|    |    ‚îî‚îÄLinear: 3-7                  [-1, 16]                  1,040
|    |    ‚îî‚îÄReLU: 3-8                    [-1, 16]                  --
|    ‚îî‚îÄLinear: 2-5                       [-1, 1]                   17
==========================================================================================
Total params: 4,236,769
Trainable params: 4,236,769
Non-trainable params: 0
Total mult-adds (M): 12.71
==========================================================================================
Input size (MB): 0.06
Forward/backward pass size (MB): 0.00
Params size (MB): 16.16
Estimated Total Size (MB): 16.23
==========================================================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">CNN</span><span class="p">(</span><span class="n">input_channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
‚îú‚îÄSequential: 1-1                        [-1, 1]                   --
|    ‚îî‚îÄSequential: 2-1                   [-1, 3, 128, 128]         --
|    |    ‚îî‚îÄConv2d: 3-1                  [-1, 3, 128, 128]         30
|    |    ‚îî‚îÄReLU: 3-2                    [-1, 3, 128, 128]         --
|    ‚îî‚îÄSequential: 2-2                   [-1, 3, 128, 128]         --
|    |    ‚îî‚îÄConv2d: 3-3                  [-1, 3, 128, 128]         84
|    |    ‚îî‚îÄReLU: 3-4                    [-1, 3, 128, 128]         --
|    ‚îî‚îÄSequential: 2-3                   [-1, 3, 128, 128]         --
|    |    ‚îî‚îÄConv2d: 3-5                  [-1, 3, 128, 128]         84
|    |    ‚îî‚îÄReLU: 3-6                    [-1, 3, 128, 128]         --
|    ‚îî‚îÄSequential: 2-4                   [-1, 3, 128, 128]         --
|    |    ‚îî‚îÄConv2d: 3-7                  [-1, 3, 128, 128]         84
|    |    ‚îî‚îÄReLU: 3-8                    [-1, 3, 128, 128]         --
|    ‚îî‚îÄSequential: 2-5                   [-1, 3, 128, 128]         --
|    |    ‚îî‚îÄConv2d: 3-9                  [-1, 3, 128, 128]         84
|    |    ‚îî‚îÄReLU: 3-10                   [-1, 3, 128, 128]         --
|    ‚îî‚îÄFlatten: 2-6                      [-1, 49152]               --
|    ‚îî‚îÄLinear: 2-7                       [-1, 1]                   49,153
==========================================================================================
Total params: 49,519
Trainable params: 49,519
Non-trainable params: 0
Total mult-adds (M): 5.85
==========================================================================================
Input size (MB): 0.06
Forward/backward pass size (MB): 1.88
Params size (MB): 0.19
Estimated Total Size (MB): 2.13
==========================================================================================
</pre></div>
</div>
</div>
</div>
<p>We don‚Äôt even have any pooling and our CNN still has a ‚Äúmeager‚Äù 49,519 parameters vs 4,236,769 for the fully-connected network. This is a somewhat arbitray comparison but it proves my point.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-mds572-py"
        },
        kernelOptions: {
            kernelName: "conda-env-mds572-py",
            path: "./chapters"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-mds572-py'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="chapter4_neural-networks-pt2.html" title="previous page">Chapter 4: Training Neural Networks</a>
    <a class='right-next' id="next-link" href="chapter6_cnns-pt2.html" title="next page">Chapter 6: Advanced Convolutional Neural Networks</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Tomas Beuzen<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>